"""Container AI Server - HTTP interface for CloudRun (Async Task Pattern)"""
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import Dict, Optional
from datetime import datetime
import logging
import sys
import uuid
import traceback

from agent.models import AnthropicModelProvider
from agent.deep_agent import RefactorAgent

# é…ç½® logging è¼¸å‡ºåˆ° stdoutï¼ˆç¢ºä¿æ—¥èªŒå¯è¢«æ”¶é›†ï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)

app = FastAPI(title="AI Server", version="1.0.0")
logger = logging.getLogger(__name__)

# ä»»å‹™ç‹€æ…‹æšèˆ‰
class TaskStatus:
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"

# å…§å­˜ä»»å‹™å„²å­˜ï¼ˆå–®å®¹å™¨å…§æœ‰æ•ˆï¼‰
tasks: Dict[str, Dict] = {}

# æ—¥èªŒå„²å­˜ï¼ˆç”¨æ–¼ streamï¼‰
task_logs: Dict[str, list] = {}

class RunRequest(BaseModel):
    init_prompt: str
    verbose: bool = True

class CloneRequest(BaseModel):
    repo_url: str
    branch: str = "main"

class RunResponse(BaseModel):
    task_id: str
    status: str
    message: str

class TaskStatusResponse(BaseModel):
    task_id: str
    status: str
    created_at: str
    started_at: Optional[str] = None
    finished_at: Optional[str] = None
    error_message: Optional[str] = None


def log_task(task_id: str, message: str):
    """è¨˜éŒ„ä»»å‹™æ—¥èªŒï¼ˆç”¨æ–¼ streamï¼‰"""
    if task_id not in task_logs:
        task_logs[task_id] = []
    timestamp = datetime.utcnow().isoformat()
    task_logs[task_id].append({"timestamp": timestamp, "message": message})
    logger.info(f"[{task_id}] {message}")


def execute_agent(task_id: str, init_prompt: str, verbose: bool):
    """èƒŒæ™¯åŸ·è¡Œ Agentï¼ˆåœ¨ BackgroundTasks ä¸­åŸ·è¡Œï¼‰"""
    try:
        # åˆå§‹åŒ–æ—¥èªŒ
        task_logs[task_id] = []

        # æ›´æ–°ç‹€æ…‹ç‚º RUNNING
        tasks[task_id]["status"] = TaskStatus.RUNNING
        tasks[task_id]["started_at"] = datetime.utcnow().isoformat()

        print(f"ğŸš€ [DEBUG] Task {task_id}: é–‹å§‹åŸ·è¡Œ", flush=True)
        log_task(task_id, "ğŸš€ é–‹å§‹åŸ·è¡Œ Agent")

        # åˆå§‹åŒ– LLM
        print(f"ğŸ”§ [DEBUG] Task {task_id}: åˆå§‹åŒ– LLM", flush=True)
        log_task(task_id, "ğŸ”§ åˆå§‹åŒ– LLM...")
        provider = AnthropicModelProvider()
        model = provider.get_model()
        print(f"âœ… [DEBUG] Task {task_id}: LLM åˆå§‹åŒ–å®Œæˆ", flush=True)
        log_task(task_id, "âœ… LLM åˆå§‹åŒ–å®Œæˆ")

        # å»ºç«‹ä¸¦åŸ·è¡Œ RefactorAgent
        print(f"ğŸ¤– [DEBUG] Task {task_id}: å»ºç«‹ RefactorAgent", flush=True)
        log_task(task_id, "ğŸ¤– å»ºç«‹ RefactorAgent...")
        agent = RefactorAgent(model, verbose=verbose)
        print(f"âœ… [DEBUG] Task {task_id}: RefactorAgent å»ºç«‹å®Œæˆ", flush=True)
        log_task(task_id, "âœ… RefactorAgent å»ºç«‹å®Œæˆ")

        # å®šç¾©äº‹ä»¶å›èª¿å‡½æ•¸ï¼Œå°‡ chunk äº‹ä»¶è½‰ç™¼åˆ°æ—¥èªŒ
        def handle_chunk_event(event_type: str, data: dict):
            """è™•ç† ChunkParser çš„äº‹ä»¶"""
            import json
            # å°‡äº‹ä»¶åºåˆ—åŒ–ç‚º JSON ä¸¦è¨˜éŒ„
            event_log = {
                "event_type": event_type,
                "data": data
            }
            log_task(task_id, f"[{event_type}] {json.dumps(data, ensure_ascii=False, default=str)}")

        print(f"â–¶ï¸  [DEBUG] Task {task_id}: é–‹å§‹åŸ·è¡Œ Agent", flush=True)
        log_task(task_id, f"â–¶ï¸  åŸ·è¡Œ Agentï¼Œinit_prompt: {init_prompt[:100]}...")
        agent.run(user_message=init_prompt, event_callback=handle_chunk_event)

        # æ¨™è¨˜å®Œæˆ
        tasks[task_id]["status"] = TaskStatus.SUCCESS
        tasks[task_id]["finished_at"] = datetime.utcnow().isoformat()
        print(f"âœ… [DEBUG] Task {task_id}: Agent åŸ·è¡Œå®Œæˆ", flush=True)
        log_task(task_id, "âœ… Agent åŸ·è¡Œå®Œæˆ")

    except Exception as e:
        error_msg = f"Agent execution failed: {str(e)}"
        print(f"âŒ [DEBUG] Task {task_id}: éŒ¯èª¤ - {error_msg}", flush=True)
        print(f"[DEBUG] Traceback:\n{traceback.format_exc()}", flush=True)
        log_task(task_id, f"âŒ éŒ¯èª¤: {error_msg}")
        log_task(task_id, f"Traceback: {traceback.format_exc()}")
        logger.error(f"[{task_id}] {error_msg}\n{traceback.format_exc()}")
        tasks[task_id]["status"] = TaskStatus.FAILED
        tasks[task_id]["error_message"] = error_msg
        tasks[task_id]["finished_at"] = datetime.utcnow().isoformat()


@app.post("/run", response_model=RunResponse)
async def run_agent(request: RunRequest, background_tasks: BackgroundTasks):
    """å•Ÿå‹• Agent åŸ·è¡Œï¼ˆç•°æ­¥æ¨¡å¼ï¼‰

    ç«‹å³è¿”å› task_idï¼ŒAgent åœ¨èƒŒæ™¯åŸ·è¡Œã€‚
    ä½¿ç”¨ GET /tasks/{task_id} æŸ¥è©¢åŸ·è¡Œç‹€æ…‹ã€‚
    """
    # ç”Ÿæˆå”¯ä¸€ task_id
    task_id = str(uuid.uuid4())

    # å»ºç«‹ä»»å‹™è¨˜éŒ„
    tasks[task_id] = {
        "task_id": task_id,
        "status": TaskStatus.PENDING,
        "init_prompt": request.init_prompt,
        "created_at": datetime.utcnow().isoformat(),
        "started_at": None,
        "finished_at": None,
        "error_message": None,
    }

    # å•Ÿå‹•èƒŒæ™¯ä»»å‹™
    background_tasks.add_task(
        execute_agent,
        task_id=task_id,
        init_prompt=request.init_prompt,
        verbose=request.verbose
    )

    logger.info(f"[{task_id}] ä»»å‹™å·²å»ºç«‹ï¼Œé–‹å§‹èƒŒæ™¯åŸ·è¡Œ")

    return RunResponse(
        task_id=task_id,
        status=TaskStatus.PENDING,
        message="Agent ä»»å‹™å·²å•Ÿå‹•ï¼Œæ­£åœ¨èƒŒæ™¯åŸ·è¡Œ"
    )


@app.get("/tasks/{task_id}", response_model=TaskStatusResponse)
async def get_task_status(task_id: str):
    """æŸ¥è©¢ä»»å‹™åŸ·è¡Œç‹€æ…‹"""
    if task_id not in tasks:
        raise HTTPException(status_code=404, detail="Task not found")

    task = tasks[task_id]
    return TaskStatusResponse(
        task_id=task["task_id"],
        status=task["status"],
        created_at=task["created_at"],
        started_at=task.get("started_at"),
        finished_at=task.get("finished_at"),
        error_message=task.get("error_message"),
    )


@app.get("/health")
async def health():
    """Health check endpoint"""
    return {"status": "healthy"}


@app.get("/tasks")
async def list_tasks():
    """åˆ—å‡ºæ‰€æœ‰ä»»å‹™ï¼ˆèª¿è©¦ç”¨ï¼‰"""
    return {"total": len(tasks), "tasks": list(tasks.values())}


@app.get("/tasks/{task_id}/stream")
async def stream_task_logs(task_id: str):
    """SSE ä¸²æµä»»å‹™åŸ·è¡Œæ—¥èªŒï¼ˆæ”¯æ´çµæ§‹åŒ–äº‹ä»¶ï¼‰"""
    from sse_starlette.sse import EventSourceResponse
    import asyncio
    import json as json_lib

    if task_id not in tasks:
        raise HTTPException(status_code=404, detail="Task not found")

    async def event_generator():
        """ç”Ÿæˆ SSE events"""
        last_index = 0

        while True:
            # æª¢æŸ¥ä»»å‹™ç‹€æ…‹
            task = tasks.get(task_id)
            if not task:
                break

            # ç™¼é€æ–°æ—¥èªŒ
            if task_id in task_logs:
                current_logs = task_logs[task_id]
                new_logs = current_logs[last_index:]

                for log in new_logs:
                    message = log['message']

                    # å˜—è©¦è§£ææ˜¯å¦ç‚ºçµæ§‹åŒ–äº‹ä»¶ï¼ˆ[event_type] JSONï¼‰
                    if message.startswith('[') and ']' in message:
                        try:
                            # æå– event_type å’Œ JSON æ•¸æ“š
                            close_bracket = message.index(']')
                            event_type = message[1:close_bracket]
                            json_data = message[close_bracket + 2:]  # è·³é '] '

                            # å˜—è©¦è§£æ JSON
                            data = json_lib.loads(json_data)

                            # ç™¼é€çµæ§‹åŒ–äº‹ä»¶
                            yield {
                                "event": event_type,
                                "data": json_lib.dumps(data, ensure_ascii=False)
                            }
                        except (ValueError, json_lib.JSONDecodeError):
                            # è§£æå¤±æ•—ï¼Œä½œç‚ºæ™®é€šæ—¥èªŒç™¼é€
                            yield {
                                "event": "log",
                                "data": json_lib.dumps({
                                    "timestamp": log['timestamp'],
                                    "message": message
                                }, ensure_ascii=False)
                            }
                    else:
                        # æ™®é€šæ—¥èªŒè¨Šæ¯
                        yield {
                            "event": "log",
                            "data": json_lib.dumps({
                                "timestamp": log['timestamp'],
                                "message": message
                            }, ensure_ascii=False)
                        }

                last_index = len(current_logs)

            # å¦‚æœä»»å‹™å®Œæˆï¼Œç™¼é€å®Œæˆäº‹ä»¶ä¸¦çµæŸ
            if task["status"] in [TaskStatus.SUCCESS, TaskStatus.FAILED]:
                yield {
                    "event": "status",
                    "data": json_lib.dumps({
                        "status": task['status'].lower(),
                        "finished_at": task.get('finished_at'),
                        "error_message": task.get('error_message')
                    }, ensure_ascii=False)
                }
                break

            await asyncio.sleep(0.5)  # æ¯ 0.5 ç§’æª¢æŸ¥ä¸€æ¬¡ï¼ˆæ›´å³æ™‚ï¼‰

    return EventSourceResponse(event_generator())
